<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on My journey from Data Analyst to Data Science</title>
    <link>/categories/machine-learning/</link>
    <description>Recent content in Machine Learning on My journey from Data Analyst to Data Science</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 31 Aug 2020 21:17:58 +0200</lastBuildDate>
    
	<atom:link href="/categories/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>The Intuition of Word Embeddings: How you Teach A Computer to Understand Text</title>
      <link>/2020/08/31/the-intuition-of-word-embeddings-how-you-teach-a-computer-to-understand-text/</link>
      <pubDate>Mon, 31 Aug 2020 21:17:58 +0200</pubDate>
      
      <guid>/2020/08/31/the-intuition-of-word-embeddings-how-you-teach-a-computer-to-understand-text/</guid>
      <description>Humans intuitively understand the meaning of words: Which words are similar, opposites or related to each other? But our machine learning models do not have this intuition. Word embeddings are numeric vectors that represent text. These vectors are learned through neural networks. The objective when creating these embedding vectors is to capture as much &amp;ldquo;meaning&amp;rdquo; as possible: Related words should be closer together than unrelated words. Also, they should be able to preserve mathematical relationships between words such as</description>
    </item>
    
  </channel>
</rss>